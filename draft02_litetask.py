# -*- coding: utf-8 -*-

# !pip install faiss - cpu langchain openai tiktoken

class draft02_litetask():
    def __init__(self):
        pass

    def run(self, msg):
        """ДЗ Light | 2 занятие| курс по дообучению ChatGPT | Гарант.ipynb

        Automatically generated by Colaboratory.

        Original file is located at
            https://colab.research.google.com/drive/abcdefgh

        На основе базы знаний СитиДрайв, используя материалы занятия, сделайте систему из 2 моделей для ответа на вопросы клиентов в чате компании: одна модель отвечает на вопрос, вторая - саммаризирует диалог, и передает в первую модель при поступлении следующего вопроса клиента. Не выводите саммаризированный диалог.

        **Инструкция для GPT**: https://docs.google.com/document/d/abcdefgh

        **База знаний**:
        https://docs.google.com/document/d/hgfedcba
        """

        # импортируем необходимые библиотеки
        from langchain.embeddings.openai import OpenAIEmbeddings
        from langchain.text_splitter import CharacterTextSplitter
        from langchain.vectorstores import FAISS
        from langchain.document_loaders import TextLoader
        import os
        import getpass
        import re
        import requests
        import openai
        from langchain.docstore.document import Document
        import logging
        from textwrap import fill
        logging.getLogger("langchain.text_splitter").setLevel(logging.ERROR)
        logging.getLogger("chromadb").setLevel(logging.ERROR)

        # Получение ключа API от пользователя и установка его как переменной окружения
        openai_key = getpass.getpass("OpenAI API Key:")
        os.environ["OPENAI_API_KEY"] = openai_key
        openai.api_key = openai_key

        # функция для загрузки документа по ссылке из гугл драйв
        def load_document_text(url: str) -> str:
            # Extract the document ID from the URL
            match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)
            if match_ is None:
                raise ValueError('Invalid Google Docs URL')
            doc_id = match_.group(1)

            # Download the document as plain text
            response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')
            response.raise_for_status()
            text = response.text

            return text

        # Инструкция для GPT, которая будет подаваться в system
        system = load_document_text()  # вставьте сюда необходимое значение
        # База знаний, которая будет подаваться в langChain
        database = load_document_text()  # вставьте сюда необходимое значение

        # делим текст на чанки и создаем индексную базу
        source_chunks = []
        splitter = CharacterTextSplitter(separator="\n", chunk_size=1024, chunk_overlap=0)

        for chunk in splitter.split_text(database):
            source_chunks.append(Document(page_content=chunk, metadata={}))

        # Инициализирум модель эмбеддингов
        embeddings = OpenAIEmbeddings()

        # Создадим индексную базу из разделенных фрагментов текста
        db = FAISS.from_documents(source_chunks, embeddings)

        MODEL_TURBO_16K = "gpt-3.5-turbo-16k"
        MODEL_TURBO_0613 = "gpt-3.5-turbo-0613"

        def create_completion(model, system, content, temperature):
            messages = [
                {"role": "system", "content": system},
                {"role": "user", "content": content}
            ]

            completion = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                temperature=temperature

            )

            return completion.choices[0].message.content

        def answer_index(system, topic, search_index, temperature=0, verbose=0):
            docs = search_index.similarity_search(topic, k=4)
            message_content = ' '.join(
                [f'\nОтрывок документа №{i + 1}\n=====================' + doc.page_content + '\n' for i, doc in
                 enumerate(docs)])
            question_content = f"Документ с информацией для ответа клиенту: {message_content}\n\nВопрос клиента: \n{topic}"
            return fill(create_completion(MODEL_TURBO_16K, system, question_content, temperature))

        def summarize_questions(dialog):
            content = "Суммаризируй следующий диалог ассистента отдела обслуживания клиентов и клиента: " + " ".join(
                dialog)
            return create_completion(MODEL_TURBO_0613,
                                     "Ты - ассистент, который умеет профессионально суммаризировать присланные тебе диалоги. Твоя задача - суммаризировать диалог, который тебе пришел. Отражай имя клиента в саммаризации",
                                     content, 0)

        def answer_user_question_dialog(system: str, db: str, user_question: str, question_history: list) -> str:
            summarized_history = ""
            if question_history:
                summarized_history = "Вот краткий обзор предыдущего диалога: " + summarize_questions(
                    [f'{q} {a or ""}' for q, a in question_history])
            input_text = f"{summarized_history}\n\nТекущий вопрос: {user_question}"
            answer_text = answer_index(system, input_text, db)
            question_history.append((user_question, answer_text or ''))
            return fill(answer_text)

        def run_dialog(system, db):
            question_history = []
            dialog = ""
            while True:
                user_question = input('Клиент: ')
                if user_question.lower() == 'stop':
                    break
                answer = answer_user_question_dialog(system, db, user_question, question_history)
                dialog += f'\nКлиент: {user_question} \n Менеджер: {answer}'
                print('\nМенеджер: ', answer)

            return

        temperature =  # вставьте сюда необходимое значение
        run_dialog()  # вставьте сюда необходимое значение


if __name__ == '__main__':
    draft02_litetask().run("")